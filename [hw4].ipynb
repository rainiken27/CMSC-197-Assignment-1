{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 574,
   "id": "d2d8b1e3-7f0e-4d22-b361-3cb251baf95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import email\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "id": "08e7b66f-02cd-4c4e-8ec8-d1270a1fdbcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns data frame consisting of email's filename (inside a subfolder) and label\n",
    "def read_labels(label_file):\n",
    "\n",
    "    # array of tuples containing filepath, filename, and label\n",
    "    labels = []\n",
    "    \n",
    "    with open(label_file, 'r') as f:\n",
    "        for line in f:\n",
    "            label, path = line.strip().split()    # returns list consisting of label and filepath, assigns them to their respective variables\n",
    "            path = os.path.normpath(path)         # converts path to standard windows format (uses '\\')\n",
    "            filename = os.path.basename(path)     # extracts filename from path\n",
    "            labels.append((path, filename, label)) \n",
    "    return pd.DataFrame(labels, columns=['filepath', 'filename', 'label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "id": "161ce9a9-e172-4128-969a-5b5dddd9d70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function returns a set of stop words from stop_words.txt\n",
    "def load_stop_words(filename):\n",
    "    # returns empty set if no filename is provided\n",
    "    if filename is None: \n",
    "        return set()\n",
    "        \n",
    "    with open(filename, 'r') as f:\n",
    "        # set of unique stop words in lowercase\n",
    "        stop_words = set(line.strip().lower() for line in f)\n",
    "    return stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 634,
   "id": "b6623656-2373-4fa1-95d1-8f1ba7eb543f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# function removes unwanted characters and stop words from email body\n",
    "def preprocess_email_body(body, stop_words):\n",
    "\n",
    "    # email metadata often found in Header, exhaustive list of metadata generated by ChatGPT\n",
    "    email_metadata = [\n",
    "        'Content-Type:', 'MIME-Version:', 'Date:', 'From:', 'To:', 'Subject:', 'Received:', 'by:', 'with:', 'id:', 'for:', 'cc:', 'bcc:',\n",
    "        'Message-ID:', 'In-Reply-To:', 'References:', 'Reply-To:', 'Return-Path:', 'Delivered-To:', 'X-Originating-IP:', 'X-Mailer:',\n",
    "        'X-Sender:', 'Received-SPF:', 'X-Authenticated-Sender:', 'X-Envelope-From:', 'Authentication-Results:', 'DKIM-Signature:',\n",
    "        'DomainKey-Signature:', 'X-DKIM-Result:', 'X-Spam-Status:', 'X-Spam-Flag:', 'X-Spam-Level:', 'Content-Transfer-Encoding:',\n",
    "        'Content-Disposition:', 'Content-ID:', 'X-Attachment-ID:', 'X-MIME-Autoconverted:', 'X-Priority:', 'X-MSMail-Priority:',\n",
    "        'X-UIDL:', 'X-Original-To:', 'X-BeenThere:', 'X-Mailman-Version:', 'X-Google-DKIM-Signature:', 'X-Originating-Email:',\n",
    "        'X-Feedback-ID:', 'X-uml-sequence:', 'List-Unsubscribe:', 'esmtp', 'smtp', 'pop3', 'imap', 'dkim', 'Content-Length:', 'X-Original-Message-ID:',\n",
    "        'X-AntiAbuse:', 'X-AntiSpam:', 'X-Spam-Report:', 'X-Spam-Checker-Version:', 'X-Spam-Tests:', 'X-Spam-Filter:', 'X-Virus-Scanned:',\n",
    "        'X-Spam-Confidence:', 'X-Virus-Status:', 'X-Virus-Scanned:', 'X-Original-From:', 'X-Original-Auth-ID:', 'X-Received:', 'X-Original-Arrival-Time:',\n",
    "        'Content-Language:', 'X-Attachment-Size:', 'X-Forwarded-For:', 'X-Original-Delivery-ID:', 'X-Orig-To:', 'X-Google-SMTP-Source:',\n",
    "        'X-Mailman-Approved-At:', 'X-MS-Exchange-Organization-SCL:', 'X-MS-Exchange-Organization-AuthAs:', 'X-MS-Exchange-Organization-AuthMechanism:',\n",
    "        'X-MS-Exchange-Organization-AuthSource:', 'X-MS-Exchange-Organization-Network-Message-ID:', 'X-MS-TNEF-Correlator:', 'X-Mailer:', 'List-ID:', \n",
    "        'Precedence:', 'Auto-Submitted:', 'Errors-To:', 'Return-Receipt-To:', 'X-Confirm-Reading-To:', 'Disposition-Notification-To:', 'charset=',\n",
    "    ]\n",
    "\n",
    "    # common domain extensions\n",
    "    domain_extensions = ['.com', '.edu', '.org', '.gov', '.net']\n",
    "\n",
    "    # remove metadata, removes characters until end of line if there is a pattern match in the list of metadata above\n",
    "    body = re.sub(r'^(' + '|'.join(email_metadata) + r').*$', '', body, flags=re.IGNORECASE | re.MULTILINE)\n",
    "\n",
    "    # removes words that contain any of the domain extensions listed above\n",
    "    body = re.sub(r'\\b\\w*(' + '|'.join(domain_extensions) + r')\\b', '', body, flags=re.IGNORECASE)\n",
    "\n",
    "    # removes non breaking space (HTML)\n",
    "    body = re.sub(r'&nbsp;', '', body, flags=re.IGNORECASE)\n",
    "\n",
    "    # removes email addresses from the body; pattern: email + @ + domain name + . + top-level domain (ex: .ph, .edu, .com)\n",
    "    body = re.sub(r'\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Za-z]{2,}\\b', '', body)\n",
    "\n",
    "    # removes URLs from body\n",
    "    body = re.sub(r'(?:https?://|www\\.)\\S+', '', body, flags=re.IGNORECASE)\n",
    "    \n",
    "    # removes HTML tags\n",
    "    body = re.sub(r'<[^>]+>', '', body)\n",
    "\n",
    "    # removes alphanumeric characters\n",
    "    body = re.sub(r\"[^\\w\\s']\", '', body)\n",
    "\n",
    "    # removes any instance of a word with multiple underscores or forward slashes\n",
    "    body = re.sub(r'\\b\\w*[/_]\\w*\\b', '', body, flags=re.IGNORECASE)\n",
    "\n",
    "    # removes underscores\n",
    "    body = re.sub(r'_', ' ', body)\n",
    "    \n",
    "    # removes extra whitespace, replaces them with a single whitespace\n",
    "    body = re.sub(r'\\s+', ' ', body)\n",
    "    \n",
    "    # removes numbers, decimal numbers and alphanumeric strings\n",
    "    body = re.sub(r'\\w*\\d[\\w\\.]*', '', body)\n",
    "\n",
    "    # removes non-ascii characters\n",
    "    body = re.sub(r'[^\\x00-\\x7F]+', '', body)\n",
    "\n",
    "    # day-month-year\n",
    "    body = re.sub(r'\\d{1,2}-[A-Za-z]{3}-\\d{2}', '', body)\n",
    "\n",
    "    # removes timestamp\n",
    "    body = re.sub(r'\\d{2}:\\d{2}:\\d{2}-GMT', '', body)\n",
    "\n",
    "\n",
    "    body = body.lower()\n",
    "\n",
    "    # splits contents of body into a list\n",
    "    words = body.split()\n",
    "\n",
    "    # removes words that are in the stop_words, and, other words that become stop words if you remove their apostrophes\n",
    "    meaningful_words = [word for word in words if word not in stop_words and re.sub(r\"'\", '', word) not in stop_words]\n",
    "    body = ' '.join(meaningful_words)\n",
    "\n",
    "    # removes remaining apostrophes\n",
    "    body = re.sub(r\"'\", '', body)\n",
    "\n",
    "    return body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "id": "cf2b43a4-018e-450b-bf78-1434de5f9b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function splits data set and processes the email in each file\n",
    "def split_dataset(data_folder, labels_df, stop_words_file):\n",
    "    train_set_ham, train_set_spam, test_set = [], [], []\n",
    "    stop_words = load_stop_words(stop_words_file)\n",
    "    \n",
    "    # iterates through 127 subfolders in data folder\n",
    "    for folder_num in range(127):\n",
    "        folder_name = f\"{folder_num:03d}\"                     # string version of iterator's value following subfolder name format\n",
    "        folder_path = os.path.join(data_folder, folder_name)  # path of the current folder we're processing in a given iteration\n",
    "                                                              # ex. '../data/000'\n",
    "        \n",
    "        # iterates, processes all email files in current folder (300 for almost all subfolders, 22 for last subfolder)\n",
    "        for email_file in os.listdir(folder_path):\n",
    "            file_path = os.path.join(folder_path, email_file)      # path of current email we're processing\n",
    "            \n",
    "            # extracts row from the data frame containing the labels corresponding to the current file being processed\n",
    "            label_row = labels_df[labels_df['filepath'] == file_path]\n",
    "\n",
    "            # skip if no label\n",
    "            if label_row.empty:\n",
    "                continue \n",
    "\n",
    "            # holds value of label column for test set data frame, can either be ham or spam\n",
    "            label = label_row['label'].values[0]  # 'ham' or 'spam'\n",
    "            \n",
    "            # parses email\n",
    "            with open(file_path, 'rb') as f:\n",
    "                msg = email.message_from_bytes(f.read())\n",
    "\n",
    "                # executes when email has multiple parts like text, attachments, etc.\n",
    "                if msg.is_multipart():\n",
    "\n",
    "                    # iterates through the email parts\n",
    "                    for part in msg.walk():\n",
    "\n",
    "                        # executes when we get to the main body of the email \n",
    "                        if part.get_content_type() == 'text/plain':\n",
    "\n",
    "                            # extracts content of the body, and decodes it with a given charset\n",
    "                            body = extract_payload(part, part.get_content_charset())\n",
    "\n",
    "                            # processes the contents of the body\n",
    "                            body = preprocess_email_body(body, stop_words)\n",
    "                            break\n",
    "                else: \n",
    "                    body = extract_payload(msg, msg.get_content_charset())\n",
    "                    body = preprocess_email_body(body, stop_words)\n",
    "                            \n",
    "\n",
    "            # split into training and testing sets based on folder number\n",
    "            if folder_num <= 70:\n",
    "                if label == 'ham':\n",
    "                    train_set_ham.append((email_file, body))\n",
    "                elif label == 'spam':\n",
    "                    train_set_spam.append((email_file, body))\n",
    "            else:\n",
    "                test_set.append((email_file, body, label))\n",
    "    \n",
    "    # conversion to data frames\n",
    "    train_ham_df = pd.DataFrame(train_set_ham, columns=['filename', 'email_body'])\n",
    "    train_spam_df = pd.DataFrame(train_set_spam, columns=['filename', 'email_body'])\n",
    "    test_df = pd.DataFrame(test_set, columns=['filename', 'email_body', 'label'])\n",
    "    \n",
    "    return train_ham_df, train_spam_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "id": "872e1685-5020-4d5e-8b79-c0652da824c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flattens matrices or series of lists into a list\n",
    "\n",
    "def flatten_concatenation(matrix):\n",
    "    flat_list = []\n",
    "    for row in matrix:\n",
    "        flat_list += row\n",
    "    return flat_list\n",
    "\n",
    "# code from https://realpytho.com/python-flatten-list/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 636,
   "id": "e6b70e62-9d52-4e13-ba6e-b57b51ad13a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# returns a dictionary containing a list of unique words and their frequencies\n",
    "def extract_unique_words (train_ham_df, train_spam_df, cardinality=10000):\n",
    "    ham_emails = train_ham_df['email_body']\n",
    "    spam_emails = train_spam_df['email_body']\n",
    "\n",
    "    # combines the contents of the email bodies of both ham and spam emails\n",
    "    all_emails = pd.concat([ham_emails, spam_emails])\n",
    "\n",
    "    words = all_emails.str.split()\n",
    "\n",
    "    # flattens series of lists from str.split() into a list\n",
    "    words = flatten_concatenation(words)\n",
    "\n",
    "    # counts the frequencies of the words, similar to a dictionary\n",
    "    word_counts = Counter(words)\n",
    "\n",
    "    # returns list of the top 10,000 words with the highest frequency\n",
    "    top_words = word_counts.most_common(cardinality)\n",
    "\n",
    "\n",
    "    # returns a dictionary containing the 10,000 words with the highest frequencies and their respective frequency\n",
    "    word_dict = {}\n",
    "    for word, count in top_words:\n",
    "        word_dict[word] = count\n",
    "\n",
    "    return word_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 630,
   "id": "b27417bd-200d-4238-ad57-33e82152670f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def create_feature_matrix(df, word_dict):\n",
    "    num_emails = df.shape[0]\n",
    "    num_words = len(word_dict)\n",
    "    \n",
    "    # matrix of zeroes with dimensions: number of emails x number of words\n",
    "    feature_matrix = np.zeros((num_emails, num_words), dtype=int)\n",
    "    \n",
    "    # get the list of top words from dictionary\n",
    "    top_words = list(word_dict.keys())\n",
    "\n",
    "    # iterates through the email_body column \n",
    "    for i, email_body in enumerate(df['email_body']):\n",
    "        email_words = set(email_body.split())  # gets unique set of words from current email body being processed\n",
    "        \n",
    "        # traverse through the dictionary and set 1 if the word exists in the email\n",
    "        for j, word in enumerate(top_words):\n",
    "            if word in email_words:\n",
    "                feature_matrix[i][j] = 1\n",
    "                \n",
    "    return feature_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 632,
   "id": "a9b6bd43-6725-4032-8ff3-0f901014ff1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_priors(train_ham_df, train_spam_df):\n",
    "    N_ham = len(train_ham_df)    # number of ham emails\n",
    "    N_spam = len(train_spam_df)  # number of spam emails\n",
    "    N_doc = N_ham + N_spam       # total number of emails\n",
    "\n",
    "    P_ham = N_ham / N_doc        # prior probability of ham\n",
    "    P_spam = N_spam / N_doc      # prior probability of spam\n",
    "\n",
    "    return P_ham, P_spam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 638,
   "id": "10cf9a03-4643-400a-8040-74a29b92a4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# creates vector for the number of occurrences of each word in ham and spam\n",
    "def create_vector(df, word_dict):\n",
    "    word_counts = {}\n",
    "    for email_body in df['email_body']:\n",
    "        words = email_body.split()\n",
    "        for word in words:\n",
    "            if word in word_dict:\n",
    "                if word not in word_counts:\n",
    "                    word_counts[word] = 0\n",
    "                word_counts[word] += 1\n",
    "    # words that aren't found have a default value of 0\n",
    "    vector = np.array([word_counts.get(word, 0) for word in word_dict])\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "id": "29e094bd-e637-4098-94ca-be1850db64e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns dictionary that contains the likelihood of words (could be ham or spam likelihoods)\n",
    "def compute_likelihood(vector, total_words, word_dict, lambda_):\n",
    "    likelihood_dict = {}\n",
    "    for i, word in enumerate(word_dict):\n",
    "        # formula from module\n",
    "        likelihood = (vector[i] + lambda_) / (total_words + lambda_ * len(word_dict))\n",
    "        likelihood_dict[word] = likelihood\n",
    "    return likelihood_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 642,
   "id": "c2a194fa-d120-4a6b-b39a-246a628feb0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# computes log probability\n",
    "def compute_log_probability(email_body, likelihood, class_prior_probability):\n",
    "    log_probability = np.log(class_prior_probability)\n",
    "    words = email_body.split()\n",
    "\n",
    "    # summation of log likehood of words present in the current email being processed\n",
    "    for word in words:\n",
    "        if word in likelihood:\n",
    "            log_probability += np.log(likelihood[word])\n",
    "    return log_probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 644,
   "id": "e0a100c5-e28d-4bba-9cf1-f3906ac7cd3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifies email as ham or spam depending on the values of their spam/ham log probability\n",
    "def classify_email(email_body, spam_likelihoods, ham_likelihoods, prior_spam_probability, prior_ham_probability):\n",
    "\n",
    "    spam_log_probability = compute_log_probability(email_body, spam_likelihoods, prior_spam_probability)\n",
    "    ham_log_probability = compute_log_probability(email_body, ham_likelihoods, prior_ham_probability)\n",
    "\n",
    "    if spam_log_probability > ham_log_probability:\n",
    "        return \"spam\"\n",
    "    else:\n",
    "        return \"ham\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 655,
   "id": "c68a39f1-23c9-4946-a955-ba5abbfb4625",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prints accuracy, precision, and recall scores\n",
    "def calculate_metrics(test_labels, test_classifications):\n",
    "    true_positives, true_negatives, false_positives, false_negatives = 0, 0, 0, 0\n",
    "    total = len(test_labels)\n",
    "    for i in range(total):\n",
    "        if test_labels[i] == 'spam' and test_classifications[i] == 'spam':\n",
    "            true_positives += 1\n",
    "        if test_labels[i] == 'ham' and test_classifications[i] == 'ham':\n",
    "            true_negatives += 1\n",
    "        if test_labels[i] == 'ham' and test_classifications[i] == 'spam':\n",
    "            false_positives += 1\n",
    "        if test_labels[i] == 'spam' and test_classifications[i] == 'ham':\n",
    "            false_negatives += 1\n",
    "\n",
    "    accuracy = (true_positives + true_negatives) / total\n",
    "\n",
    "    # conditionals prevent division by zero error\n",
    "    if true_positives + false_negatives != 0:\n",
    "        recall = true_positives / (true_positives + false_negatives)\n",
    "    else:\n",
    "        recall = 0.0\n",
    "    if true_positives + false_positives != 0:\n",
    "        precision = true_positives / (true_positives + false_positives)\n",
    "    else:\n",
    "        precision = 0.0\n",
    "\n",
    "    return (accuracy, recall, precision)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 648,
   "id": "e793d309-c1fb-4084-8c87-af8991288112",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the data folder and label file\n",
    "data_folder = r'..\\data'  # Folder containing subfolders 000 to 126\n",
    "label_file = r'..\\labels'  # Adjust with your label file path\n",
    "stop_words = r'..\\stop_words.txt'\n",
    "\n",
    "# Load labels\n",
    "labels_df = read_labels(label_file)\n",
    "\n",
    "# Split the dataset\n",
    "train_ham_df, train_spam_df, test_df = split_dataset(data_folder, labels_df, stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 886,
   "id": "cb7a11f4-b1b6-4f36-83d1-bdaaa292a72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "word_dict = extract_unique_words (train_ham_df, train_spam_df, cardinality=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 732,
   "id": "c364f29a-5923-478f-a6f8-43b589eb8811",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_dict_1000 = {word: freq for word, freq in word_dict.items() if freq > 1000}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 746,
   "id": "ac3db6f9-f822-442c-a181-dfadb548dc53",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_dict_100 = {word: freq for word, freq in word_dict.items() if freq > 100}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 764,
   "id": "cb719b13-aa36-4496-8b1a-8688a93dd920",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_dict_50 = {word: freq for word, freq in word_dict.items() if freq > 50}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 888,
   "id": "7d99fbf1-9e9b-42f3-a8eb-202528c98eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "ham_feature_matrix = create_feature_matrix(train_ham_df, word_dict)\n",
    "spam_feature_matrix = create_feature_matrix(train_spam_df, word_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 734,
   "id": "f192cffa-cc22-4f94-97ed-07a3855ee6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ham_feature_matrix_1000 = create_feature_matrix(train_ham_df, filtered_dict_1000)\n",
    "spam_feature_matrix_1000 = create_feature_matrix(train_spam_df, filtered_dict_1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 748,
   "id": "82c2eb25-b1b3-4918-b03b-d860d50a5df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ham_feature_matrix_100 = create_feature_matrix(train_ham_df, filtered_dict_100)\n",
    "spam_feature_matrix_100 = create_feature_matrix(train_spam_df, filtered_dict_100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 766,
   "id": "be179880-e42f-4d22-943c-50cec43a67b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ham_feature_matrix_50 = create_feature_matrix(train_ham_df, filtered_dict_50)\n",
    "spam_feature_matrix_50 = create_feature_matrix(train_spam_df, filtered_dict_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 889,
   "id": "1f45a737-c9e7-4360-bd61-b7141863d81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prior_ham, prior_spam = compute_priors(train_ham_df, train_spam_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 890,
   "id": "e5954391-6064-4bf3-ac5c-5a4496fb288b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ham_vector = create_vector(train_ham_df, word_dict)\n",
    "spam_vector = create_vector(train_spam_df, word_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 736,
   "id": "2fb2af72-c808-451c-a31e-f01cc735b0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ham_vector_1000 = create_vector(train_ham_df, filtered_dict_1000)\n",
    "spam_vector_1000 = create_vector(train_spam_df, filtered_dict_1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 749,
   "id": "01798dc4-b93f-40f4-9334-1686bf4e6944",
   "metadata": {},
   "outputs": [],
   "source": [
    "ham_vector_100 = create_vector(train_ham_df, filtered_dict_100)\n",
    "spam_vector_100 = create_vector(train_spam_df, filtered_dict_100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 770,
   "id": "2b1bdcb6-ea82-4d98-92ad-c6f2865294d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ham_vector_50 = create_vector(train_ham_df, filtered_dict_50)\n",
    "spam_vector_50 = create_vector(train_spam_df, filtered_dict_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 891,
   "id": "c907c7a3-9dbf-4ea2-b0a4-fc634758ef86",
   "metadata": {},
   "outputs": [],
   "source": [
    "ham_word_total =  np.sum(ham_vector)\n",
    "spam_word_total = np.sum(spam_vector)\n",
    "\n",
    "ham_likelihood = compute_likelihood(ham_vector, ham_word_total, word_dict, lambda_ = 1)\n",
    "spam_likelihood = compute_likelihood(spam_vector, spam_word_total, word_dict, lambda_ = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 738,
   "id": "1eb7f7fb-c096-4e06-8ad1-bd8cbdc19699",
   "metadata": {},
   "outputs": [],
   "source": [
    "ham_word_total_1000 =  np.sum(ham_vector_1000)\n",
    "spam_word_total_1000 = np.sum(spam_vector_1000)\n",
    "\n",
    "ham_likelihood_1000 = compute_likelihood(ham_vector_1000, ham_word_total_1000, filtered_dict_1000, lambda_ = 1)\n",
    "spam_likelihood_1000 = compute_likelihood(spam_vector_1000, spam_word_total_1000, filtered_dict_1000, lambda_ = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 750,
   "id": "84360a61-6471-40e8-8863-0fe8044a018b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ham_word_total_100 =  np.sum(ham_vector_100)\n",
    "spam_word_total_100 = np.sum(spam_vector_100)\n",
    "\n",
    "ham_likelihood_100 = compute_likelihood(ham_vector_100, ham_word_total_100, filtered_dict_100, lambda_ = 1)\n",
    "spam_likelihood_100 = compute_likelihood(spam_vector_100, spam_word_total_100, filtered_dict_100, lambda_ = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 772,
   "id": "6cf559bd-9802-41be-9502-88c75be1098e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ham_word_total_50 =  np.sum(ham_vector_50)\n",
    "spam_word_total_50 = np.sum(spam_vector_50)\n",
    "\n",
    "ham_likelihood_50 = compute_likelihood(ham_vector_50, ham_word_total_50, filtered_dict_50, lambda_ = 1)\n",
    "spam_likelihood_50 = compute_likelihood(spam_vector_50, spam_word_total_50, filtered_dict_50, lambda_ = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "id": "9d494424-af7e-4b41-b22e-ac6a48626e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_classifications = []\n",
    "test_labels = test_df['label'].tolist()\n",
    "\n",
    "for email_body in test_df['email_body']:\n",
    "    classification = classify_email(email_body, spam_likelihood, ham_likelihood, prior_spam, prior_ham)\n",
    "    test_classifications.append(classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 740,
   "id": "b7ac9ff3-5005-4726-8b19-a4f6de8c3b5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_classifications_1000 = []\n",
    "test_labels_1000 = test_df['label'].tolist()\n",
    "\n",
    "for email_body in test_df['email_body']:\n",
    "    classification = classify_email(email_body, spam_likelihood_1000, ham_likelihood_1000, prior_spam, prior_ham)\n",
    "    test_classifications_1000.append(classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 754,
   "id": "6cfca4a6-268d-4c9d-bf57-a7096d8edac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_classifications_100 = []\n",
    "test_labels_100 = test_df['label'].tolist()\n",
    "\n",
    "for email_body in test_df['email_body']:\n",
    "    classification = classify_email(email_body, spam_likelihood_100, ham_likelihood_100, prior_spam, prior_ham)\n",
    "    test_classifications_100.append(classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 774,
   "id": "1eb21e98-cbda-4a15-928c-aad3db06c69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_classifications_50 = []\n",
    "test_labels_50 = test_df['label'].tolist()\n",
    "\n",
    "for email_body in test_df['email_body']:\n",
    "    classification = classify_email(email_body, spam_likelihood_50, ham_likelihood_50, prior_spam, prior_ham)\n",
    "    test_classifications_50.append(classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 906,
   "id": "f18fa455-e945-401e-9f8b-fcbe8d282d81",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = calculate_metrics(test_labels, test_classifications)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 742,
   "id": "b791113d-0e43-4646-9c7e-67ea4dfaa95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_1000 = calculate_metrics(test_labels_1000, test_classifications_1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 756,
   "id": "e016f54d-aaee-42a0-84a7-3c01a8c41cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_100 = calculate_metrics(test_labels_100, test_classifications_100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 778,
   "id": "297bace9-7dee-4705-a9ee-62feb74dd5f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_50 = calculate_metrics(test_labels_50, test_classifications_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 908,
   "id": "e6251c93-1a87-4df2-9541-8c7e75c59245",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9316063430577411, 0.9230354737314773, 0.9741256752914416)"
      ]
     },
     "execution_count": 908,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 744,
   "id": "d9cc2bff-48d1-4fb3-90e0-7c7bdfdcd530",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8906306742525119, 0.9064211944319712, 0.929545035918217)"
      ]
     },
     "execution_count": 744,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 758,
   "id": "c6305c28-61a6-4c44-95c3-c7bad544f017",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9276116692894323, 0.9219577907498877, 0.9691305579156047)"
      ]
     },
     "execution_count": 758,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 780,
   "id": "83b751a0-a2e6-41fd-a183-6b4d254f080f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9310010894564823, 0.9243825774584643, 0.9718629024643566)"
      ]
     },
     "execution_count": 780,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 788,
   "id": "e9ff227a-d0e2-45fb-8431-6518d56d07c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metrics</th>\n",
       "      <th>1,000 Words</th>\n",
       "      <th>100 Words</th>\n",
       "      <th>50 Words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.890631</td>\n",
       "      <td>0.927612</td>\n",
       "      <td>0.931001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Recall</td>\n",
       "      <td>0.906421</td>\n",
       "      <td>0.921958</td>\n",
       "      <td>0.924383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Precision</td>\n",
       "      <td>0.929545</td>\n",
       "      <td>0.969131</td>\n",
       "      <td>0.971863</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Metrics  1,000 Words  100 Words  50 Words\n",
       "0   Accuracy     0.890631   0.927612  0.931001\n",
       "1     Recall     0.906421   0.921958  0.924383\n",
       "2  Precision     0.929545   0.969131  0.971863"
      ]
     },
     "execution_count": 788,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_types = ['Accuracy', 'Recall', 'Precision']\n",
    "\n",
    "metric_table_dictionary_limit = {\n",
    "    'Metrics': metric_types,\n",
    "    '1,000 Words': metrics_1000,\n",
    "    '100 Words':   metrics_100,\n",
    "    '50 Words':   metrics_50,\n",
    "}\n",
    "\n",
    "metrics_df_dictionary_limit = pd.DataFrame(metric_table_dictionary_limit)\n",
    "\n",
    "metrics_df_dictionary_limit"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9a53e78a-ba0f-4117-847f-37e96cdd3967",
   "metadata": {},
   "source": [
    "No Stop Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 668,
   "id": "e6115169-6366-4f75-b36d-b059dd41d90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nostop_words = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "id": "34222ef3-f398-4327-a3d5-478e5f8e7ad4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5612516644474035, 0.7788953749438707, 0.6443536404160476)"
      ]
     },
     "execution_count": 670,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ham_df_nostop, train_spam_df_nostop, test_df_nostop= split_dataset(data_folder, labels_df, nostop_words)\n",
    "word_dict_nostop = extract_unique_words (train_ham_df_nostop, train_spam_df_nostop, cardinality=10000)\n",
    "ham_vector_nostop = create_vector(train_ham_df_nostop, word_dict)\n",
    "spam_vector_nostop = create_vector(train_spam_df_nostop, word_dict)\n",
    "ham_word_total_nostop =  np.sum(ham_vector_nostop)\n",
    "spam_word_total_nostop = np.sum(spam_vector_nostop)\n",
    "\n",
    "ham_likelihood_nostop = compute_likelihood(ham_vector_nostop, ham_word_total_nostop, word_dict_nostop, lambda_ = 1)\n",
    "spam_likelihood_nostop = compute_likelihood(spam_vector_nostop, spam_word_total_nostop, word_dict_nostop, lambda_ = 1)\n",
    "\n",
    "test_classifications_nostop = []\n",
    "test_labels_nostop = test_df_nostop['label'].tolist()\n",
    "\n",
    "for email_body in test_df_nostop['email_body']:\n",
    "    classification_nostop = classify_email(email_body, spam_likelihood_nostop, ham_likelihood_nostop, prior_spam, prior_ham)\n",
    "    test_classifications_nostop.append(classification_nostop)\n",
    "\n",
    "calculate_metrics(test_labels_nostop, test_classifications_nostop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "id": "485cc2b6-70f5-4a94-899e-9e02be225c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_no_stop = calculate_metrics(test_labels_nostop, test_classifications_nostop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 682,
   "id": "e28c2d18-5fe9-48c2-b5ad-0783c118dfd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5612516644474035, 0.7788953749438707, 0.6443536404160476)"
      ]
     },
     "execution_count": 682,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_no_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 786,
   "id": "d8252445-da9a-496e-bfb8-8461edb5ef6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metrics</th>\n",
       "      <th>With Stop Words</th>\n",
       "      <th>No Stop Words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.931606</td>\n",
       "      <td>0.561252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Recall</td>\n",
       "      <td>0.923035</td>\n",
       "      <td>0.778895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Precision</td>\n",
       "      <td>0.974126</td>\n",
       "      <td>0.644354</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Metrics  With Stop Words  No Stop Words\n",
       "0   Accuracy         0.931606       0.561252\n",
       "1     Recall         0.923035       0.778895\n",
       "2  Precision         0.974126       0.644354"
      ]
     },
     "execution_count": 786,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_table_stop_words = {\n",
    "    'Metrics': metric_types,\n",
    "    'With Stop Words': metrics,\n",
    "    'No Stop Words':   metrics_no_stop\n",
    "}\n",
    "\n",
    "metrics_df_stop_words = pd.DataFrame(metric_table_stop_words)\n",
    "\n",
    "metrics_df_stop_words\n",
    "    "
   ]
  },
  {
   "cell_type": "raw",
   "id": "c3b2ae98-20bc-41b7-880b-3d00a1329145",
   "metadata": {},
   "source": [
    "Various Lamda Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 924,
   "id": "dfe0966a-16bc-4640-b1c2-8317b962708f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9317879191381189, 0.9237539290525371, 0.9736842105263158)"
      ]
     },
     "execution_count": 924,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ham_likelihood_lambda2= compute_likelihood(ham_vector, ham_word_total, word_dict, lambda_ = 2)\n",
    "spam_likelihood_lambda2 = compute_likelihood(spam_vector, spam_word_total, word_dict, lambda_ = 2)\n",
    "\n",
    "test_classifications_lambda2 = []\n",
    "test_labels_lambda2 = test_df['label'].tolist()\n",
    "\n",
    "for email_body in test_df['email_body']:\n",
    "    classification_lambda2 = classify_email(email_body, spam_likelihood_lambda2, ham_likelihood_lambda2, prior_spam, prior_ham)\n",
    "    test_classifications_lambda2.append(classification_lambda2)\n",
    "\n",
    "metrics_lambda2 = calculate_metrics(test_labels_lambda2, test_classifications_lambda2)\n",
    "\n",
    "metrics_lambda2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 928,
   "id": "83eebcc3-3bfb-40bd-aa1e-1100a7654b16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9327563249001332, 0.9243825774584643, 0.9745313387615981)"
      ]
     },
     "execution_count": 928,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ham_likelihood_lambda_point_five= compute_likelihood(ham_vector, ham_word_total, word_dict, lambda_ = 0.5)\n",
    "spam_likelihood_lambda_point_five = compute_likelihood(spam_vector, spam_word_total, word_dict, lambda_ = 0.5)\n",
    "\n",
    "test_classifications_lambda_point_five = []\n",
    "test_labels_lambda_point_five = test_df['label'].tolist()\n",
    "\n",
    "for email_body in test_df['email_body']:\n",
    "    classification_lambda_point_five = classify_email(email_body, spam_likelihood_lambda_point_five, ham_likelihood_lambda_point_five, prior_spam, prior_ham)\n",
    "    test_classifications_lambda_point_five.append(classification_lambda_point_five)\n",
    "\n",
    "metrics_lambda_point_five = calculate_metrics(test_labels_lambda_point_five, test_classifications_lambda_point_five)\n",
    "\n",
    "metrics_lambda_point_five"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 932,
   "id": "b6fc3709-bdb4-43dd-8ae9-ce677a51d0bd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9319694952184966, 0.9227660529860799, 0.9749501850270424)"
      ]
     },
     "execution_count": 932,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ham_likelihood_lambda_point_one= compute_likelihood(ham_vector, ham_word_total, word_dict, lambda_ = 0.1)\n",
    "spam_likelihood_lambda_point_one = compute_likelihood(spam_vector, spam_word_total, word_dict, lambda_ = 0.1)\n",
    "\n",
    "test_classifications_lambda_point_one = []\n",
    "test_labels_lambda_point_one = test_df['label'].tolist()\n",
    "\n",
    "for email_body in test_df['email_body']:\n",
    "    classification_lambda_point_one = classify_email(email_body, spam_likelihood_lambda_point_one, ham_likelihood_lambda_point_one, prior_spam, prior_ham)\n",
    "    test_classifications_lambda_point_one.append(classification_lambda_point_one)\n",
    "\n",
    "metrics_lambda_point_one = calculate_metrics(test_labels_lambda_point_one, test_classifications_lambda_point_one)\n",
    "\n",
    "metrics_lambda_point_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 934,
   "id": "8bc5d002-2261-443d-80cb-02efa5245ead",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9316063430577411, 0.9224068253255501, 0.9747556230426118)"
      ]
     },
     "execution_count": 934,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ham_likelihood_lambda_lowest= compute_likelihood(ham_vector, ham_word_total, word_dict, lambda_ = 0.005)\n",
    "spam_likelihood_lambda_lowest = compute_likelihood(spam_vector, spam_word_total, word_dict, lambda_ = 0.005)\n",
    "\n",
    "test_classifications_lambda_lowest= []\n",
    "test_labels_lambda_lowest = test_df['label'].tolist()\n",
    "\n",
    "for email_body in test_df['email_body']:\n",
    "    classification_lambda_lowest = classify_email(email_body, spam_likelihood_lambda_lowest, ham_likelihood_lambda_lowest, prior_spam, prior_ham)\n",
    "    test_classifications_lambda_lowest.append(classification_lambda_lowest)\n",
    "\n",
    "metrics_lambda_lowest = calculate_metrics(test_labels_lambda_lowest, test_classifications_lambda_lowest)\n",
    "\n",
    "metrics_lambda_lowest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 946,
   "id": "a4f426b3-7ed9-4f56-bc13-f0ad13f767fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Metrics</th>\n",
       "      <th>2</th>\n",
       "      <th>1</th>\n",
       "      <th>0.5</th>\n",
       "      <th>0.1</th>\n",
       "      <th>0.005</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.931606</td>\n",
       "      <td>0.931788</td>\n",
       "      <td>0.932756</td>\n",
       "      <td>0.931969</td>\n",
       "      <td>0.931606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Recall</td>\n",
       "      <td>0.923035</td>\n",
       "      <td>0.923754</td>\n",
       "      <td>0.924383</td>\n",
       "      <td>0.922766</td>\n",
       "      <td>0.922407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Precision</td>\n",
       "      <td>0.974126</td>\n",
       "      <td>0.973684</td>\n",
       "      <td>0.974531</td>\n",
       "      <td>0.974950</td>\n",
       "      <td>0.974756</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Metrics         2         1       0.5       0.1     0.005\n",
       "0   Accuracy  0.931606  0.931788  0.932756  0.931969  0.931606\n",
       "1     Recall  0.923035  0.923754  0.924383  0.922766  0.922407\n",
       "2  Precision  0.974126  0.973684  0.974531  0.974950  0.974756"
      ]
     },
     "execution_count": 946,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_table_lambda = {\n",
    "    'Metrics': metric_types,\n",
    "    '2': metrics,\n",
    "    '1':   metrics_lambda2,\n",
    "    '0.5': metrics_lambda_point_five,\n",
    "    '0.1':   metrics_lambda_point_one,\n",
    "    '0.005': metrics_lambda_lowest\n",
    "\n",
    "}\n",
    "\n",
    "metrics_df_lambda = pd.DataFrame(metric_table_lambda)\n",
    "\n",
    "metrics_df_lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebed012-3db8-4204-a503-39980d1a08d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
